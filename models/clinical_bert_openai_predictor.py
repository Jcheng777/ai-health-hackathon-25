#!/usr/bin/env python3
"""
ClinicalBERT + OpenAI Healthcare Claim Denial Predictor

Advanced clinical AI combining:
- ClinicalBERT (trained on MIMIC-III) for medical knowledge
- OpenAI GPT for clinical reasoning and medical interpretation
- Rule-based clinical guidelines for validation

This represents state-of-the-art medical AI for claim denial prediction.
"""

import pandas as pd
import numpy as np
import os
import json
import warnings
from typing import Dict, List, Any, Optional, Tuple
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# OpenAI integration
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# ClinicalBERT integration
try:
    from transformers import (
        AutoTokenizer, AutoModelForSequenceClassification,
        pipeline
    )
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

warnings.filterwarnings('ignore')

class ClinicalBERTOpenAIPredictor:
    """Advanced clinical AI combining ClinicalBERT + OpenAI for medical reasoning"""
    
    def __init__(self, 
                 clinical_bert_model="emilyalsentzer/Bio_ClinicalBERT",
                 openai_api_key=None):
        
        self.clinical_bert_model = clinical_bert_model
        self.openai_client = None
        self.clinical_bert_classifier = None
        self.tokenizer = None
        self.is_trained = False
        
        # Initialize medical knowledge base
        self.medical_patterns = self._initialize_medical_knowledge()
        self.clinical_guidelines = self._initialize_clinical_guidelines()
        
        # Initialize AI models
        self._initialize_clinical_bert()
        self._initialize_openai(openai_api_key)
        
        # Performance tracking
        self.prediction_history = []
        
    def _initialize_clinical_bert(self):
        """Initialize ClinicalBERT model trained on MIMIC-III"""
        if not TRANSFORMERS_AVAILABLE:
            print("‚ö†Ô∏è Transformers not available. ClinicalBERT functionality disabled.")
            return
            
        try:
            print(f"üè• Loading ClinicalBERT (MIMIC-III trained): {self.clinical_bert_model}")
            self.tokenizer = AutoTokenizer.from_pretrained(self.clinical_bert_model)
            
            # Use feature extraction for medical embeddings
            self.clinical_bert_classifier = pipeline(
                "feature-extraction",
                model=self.clinical_bert_model,
                tokenizer=self.tokenizer
            )
            print("‚úÖ ClinicalBERT loaded successfully")
            
        except Exception as e:
            print(f"‚ö†Ô∏è ClinicalBERT initialization failed: {e}")
            print("üìù Will use rule-based clinical reasoning only")
    
    def _initialize_openai(self, api_key=None):
        """Initialize OpenAI client for clinical reasoning"""
        if not OPENAI_AVAILABLE:
            print("‚ö†Ô∏è OpenAI library not available. Install with: pip install openai")
            return
            
        # Try to get API key from parameter, environment, or config
        if api_key:
            openai_key = api_key
        else:
            openai_key = os.getenv('OPENAI_API_KEY')
            
        if openai_key:
            try:
                self.openai_client = openai.OpenAI(api_key=openai_key)
                print("‚úÖ OpenAI client initialized successfully")
            except Exception as e:
                print(f"‚ö†Ô∏è OpenAI initialization failed: {e}")
        else:
            print("‚ö†Ô∏è No OpenAI API key provided. Set OPENAI_API_KEY environment variable.")
    
    def _initialize_medical_knowledge(self) -> Dict[str, Any]:
        """Initialize comprehensive medical knowledge base"""
        return {
            'high_risk_procedures': {
                '99213': 'Office visit, established patient, moderate complexity',
                '99214': 'Office visit, established patient, moderate-high complexity', 
                '99215': 'Office visit, established patient, high complexity',
                '27447': 'Total knee arthroplasty',
                '27130': 'Total hip arthroplasty',
                '64483': 'Transforaminal epidural injection, lumbar',
                '64484': 'Transforaminal epidural injection, cervical',
                '12032': 'Layer closure of wounds 2.6-7.5 cm',
                '12034': 'Layer closure of wounds 7.6-12.5 cm',
                '93000': 'Electrocardiogram, routine ECG with interpretation'
            },
            'emergency_procedures': {
                '99281': 'Emergency department visit, problem-focused',
                '99282': 'Emergency department visit, expanded problem-focused',
                '99283': 'Emergency department visit, detailed',
                '99284': 'Emergency department visit, comprehensive',
                '99285': 'Emergency department visit, comprehensive high complexity',
                '36415': 'Routine venipuncture',
                '71020': 'Radiologic examination, chest, 2 views'
            },
            'preventive_care': {
                '99391': 'Preventive medicine, infant (age under 1 year)',
                '99392': 'Preventive medicine, early childhood (age 1-4 years)',
                '99393': 'Preventive medicine, late childhood (age 5-11 years)',
                '99394': 'Preventive medicine, adolescent (age 12-17 years)',
                '99395': 'Preventive medicine, 18-39 years',
                '86803': 'Hepatitis B surface antibody',
                '82465': 'Cholesterol, serum, total'
            },
            'mental_health_diagnoses': {
                'F32': 'Major depressive disorder, single episode',
                'F33': 'Major depressive disorder, recurrent',
                'F41.1': 'Generalized anxiety disorder',
                'F43.10': 'Post-traumatic stress disorder, unspecified',
                'F31': 'Bipolar disorder'
            },
            'mental_health_procedures': {
                '90834': 'Psychotherapy, 45 minutes',
                '90837': 'Psychotherapy, 60 minutes', 
                '90847': 'Family psychotherapy with patient present'
            }
        }
    
    def _initialize_clinical_guidelines(self) -> Dict[str, Any]:
        """Initialize evidence-based clinical guidelines"""
        return {
            'approval_criteria': {
                'preventive_care': 0.95,  # High approval rate
                'emergency_care': 0.85,   # High approval for emergencies
                'mental_health': 0.75,    # Moderate approval
                'complex_procedures': 0.65, # Lower approval for complex cases
                'experimental': 0.30      # Low approval for experimental
            },
            'cost_thresholds': {
                'low_cost': 1000.0,
                'moderate_cost': 5000.0,
                'high_cost': 15000.0,
                'very_high_cost': 50000.0
            },
            'medical_necessity_factors': [
                'diagnosis_severity',
                'treatment_urgency', 
                'alternative_treatments',
                'evidence_based_guidelines',
                'patient_safety_risk'
            ]
        }
    
    def create_clinical_narrative(self, claim: Dict[str, Any]) -> str:
        """Create comprehensive clinical narrative for AI analysis"""
        
        procedure_code = str(claim.get('Procedure Code', 'Unknown'))
        diagnosis_code = str(claim.get('Diagnosis Code', 'Unknown'))
        insurance_type = str(claim.get('Insurance Type', 'Unknown'))
        billed_amount = float(claim.get('Billed Amount', 0))
        allowed_amount = float(claim.get('Allowed Amount', 0))
        paid_amount = float(claim.get('Paid Amount', 0))
        
        # Get medical descriptions
        procedure_desc = self._get_procedure_description(procedure_code)
        diagnosis_desc = self._get_diagnosis_description(diagnosis_code)
        
        clinical_narrative = f"""
HEALTHCARE CLAIM CLINICAL ASSESSMENT

PATIENT PRESENTATION:
Patient requires medical intervention for diagnosis {diagnosis_code} ({diagnosis_desc}).
Recommended treatment includes procedure {procedure_code} ({procedure_desc}).

CLINICAL INDICATION:
Primary diagnosis: {diagnosis_code} - {diagnosis_desc}
Proposed intervention: {procedure_code} - {procedure_desc}
Medical necessity assessment required for insurance authorization.

FINANCIAL SUMMARY:
- Provider charges: ${billed_amount:.2f}
- Insurance allowable: ${allowed_amount:.2f} 
- Expected reimbursement: ${paid_amount:.2f}
- Insurance coverage: {insurance_type}

CLINICAL DECISION FACTORS:
- Treatment urgency: {self._assess_urgency(procedure_code, diagnosis_code)}
- Medical complexity: {self._assess_complexity(procedure_code)}
- Evidence-based indication: {self._assess_evidence_base(procedure_code, diagnosis_code)}
- Alternative treatments available: {self._assess_alternatives(procedure_code)}

AUTHORIZATION REQUEST:
Clinical team requests approval for medically necessary care as indicated by established 
medical guidelines and evidence-based treatment protocols for {diagnosis_desc}.
"""
        
        return clinical_narrative.strip()
    
    def _get_procedure_description(self, procedure_code: str) -> str:
        """Get clinical description of procedure code"""
        all_procedures = {**self.medical_patterns['high_risk_procedures'],
                         **self.medical_patterns['emergency_procedures'],
                         **self.medical_patterns['preventive_care'],
                         **self.medical_patterns['mental_health_procedures']}
        
        return all_procedures.get(procedure_code, "Medical procedure")
    
    def _get_diagnosis_description(self, diagnosis_code: str) -> str:
        """Get clinical description of diagnosis code"""
        return self.medical_patterns['mental_health_diagnoses'].get(
            diagnosis_code, f"Medical condition {diagnosis_code}"
        )
    
    def _assess_urgency(self, procedure_code: str, diagnosis_code: str) -> str:
        """Assess treatment urgency"""
        if procedure_code in self.medical_patterns['emergency_procedures']:
            return "High - Emergency/urgent care"
        elif procedure_code in self.medical_patterns['preventive_care']:
            return "Low - Preventive/routine care"
        else:
            return "Moderate - Standard medical care"
    
    def _assess_complexity(self, procedure_code: str) -> str:
        """Assess medical complexity"""
        if procedure_code in self.medical_patterns['high_risk_procedures']:
            return "High complexity requiring specialized expertise"
        else:
            return "Standard complexity within scope of practice"
    
    def _assess_evidence_base(self, procedure_code: str, diagnosis_code: str) -> str:
        """Assess evidence-based indication"""
        return "Supported by clinical guidelines and evidence-based protocols"
    
    def _assess_alternatives(self, procedure_code: str) -> str:
        """Assess alternative treatment options"""
        if procedure_code in self.medical_patterns['emergency_procedures']:
            return "Limited - Emergency intervention required"
        else:
            return "Available - Conservative treatments may be considered"
    
    def get_clinical_bert_analysis(self, clinical_text: str) -> Dict[str, Any]:
        """Get ClinicalBERT medical knowledge analysis"""
        
        if not self.clinical_bert_classifier:
            return {'bert_confidence': 0.5, 'medical_embeddings': None}
        
        try:
            # Get medical embeddings from ClinicalBERT
            embeddings = self.clinical_bert_classifier(clinical_text)
            
            # Calculate medical complexity score based on embeddings
            if embeddings and len(embeddings[0]) > 0:
                # Use embedding magnitude as medical complexity indicator
                embedding_vector = np.array(embeddings[0][0])  # First token embedding
                medical_complexity = np.linalg.norm(embedding_vector) / 100.0  # Normalize
                medical_complexity = min(1.0, max(0.1, medical_complexity))
            else:
                medical_complexity = 0.5
            
            return {
                'bert_confidence': medical_complexity,
                'medical_embeddings': embeddings,
                'clinical_understanding': 'ClinicalBERT medical knowledge applied'
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è ClinicalBERT analysis error: {e}")
            return {'bert_confidence': 0.5, 'medical_embeddings': None}
    
    def get_openai_clinical_reasoning(self, clinical_text: str) -> Dict[str, Any]:
        """Get OpenAI clinical reasoning and medical interpretation"""
        
        if not self.openai_client:
            return self._fallback_clinical_reasoning(clinical_text)
        
        try:
            prompt = f"""
You are an expert medical reviewer analyzing a healthcare claim for authorization.
Please review the clinical information and provide your assessment.

{clinical_text}

Please provide:
1. Medical necessity assessment (High/Medium/Low)
2. Approval recommendation (Approve/Deny/Review)
3. Clinical reasoning (2-3 key points)
4. Risk factors identified
5. Confidence level (0.0-1.0)

Respond in JSON format:
{{
    "medical_necessity": "High|Medium|Low",
    "recommendation": "Approve|Deny|Review", 
    "clinical_reasoning": ["reason1", "reason2", "reason3"],
    "risk_factors": ["factor1", "factor2"],
    "confidence": 0.85,
    "clinical_notes": "Additional clinical context"
}}
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are an expert medical reviewer with deep knowledge of clinical guidelines, medical necessity criteria, and insurance authorization protocols."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            # Parse OpenAI response
            ai_response = response.choices[0].message.content.strip()
            
            # Try to parse JSON response
            try:
                clinical_assessment = json.loads(ai_response)
                
                # Convert recommendation to probability
                if clinical_assessment.get('recommendation') == 'Approve':
                    approval_prob = clinical_assessment.get('confidence', 0.8)
                elif clinical_assessment.get('recommendation') == 'Review':
                    approval_prob = 0.5  # Neutral for review cases
                else:  # Deny
                    approval_prob = 1.0 - clinical_assessment.get('confidence', 0.8)
                
                return {
                    'openai_confidence': approval_prob,
                    'medical_necessity': clinical_assessment.get('medical_necessity', 'Medium'),
                    'clinical_reasoning': clinical_assessment.get('clinical_reasoning', []),
                    'risk_factors': clinical_assessment.get('risk_factors', []),
                    'clinical_notes': clinical_assessment.get('clinical_notes', ''),
                    'raw_response': ai_response
                }
                
            except json.JSONDecodeError:
                # Fallback parsing for non-JSON responses
                approval_prob = 0.7 if 'approve' in ai_response.lower() else 0.3
                return {
                    'openai_confidence': approval_prob,
                    'medical_necessity': 'Medium',
                    'clinical_reasoning': ['OpenAI clinical analysis provided'],
                    'risk_factors': ['Standard medical review'],
                    'clinical_notes': ai_response[:200] + "...",
                    'raw_response': ai_response
                }
                
        except Exception as e:
            print(f"‚ö†Ô∏è OpenAI analysis error: {e}")
            return self._fallback_clinical_reasoning(clinical_text)
    
    def _fallback_clinical_reasoning(self, clinical_text: str) -> Dict[str, Any]:
        """Fallback clinical reasoning when OpenAI unavailable"""
        
        # Rule-based clinical assessment
        approval_prob = 0.75  # Base approval rate
        reasoning = ["Rule-based clinical assessment"]
        risk_factors = []
        
        text_lower = clinical_text.lower()
        
        # Adjust based on text analysis
        if 'emergency' in text_lower or 'urgent' in text_lower:
            approval_prob += 0.15
            reasoning.append("Emergency/urgent care indication")
        
        if 'preventive' in text_lower or 'routine' in text_lower:
            approval_prob += 0.10
            reasoning.append("Preventive care typically covered")
        
        if 'experimental' in text_lower or 'investigational' in text_lower:
            approval_prob -= 0.25
            risk_factors.append("Experimental treatment")
        
        if 'high complexity' in text_lower:
            approval_prob -= 0.10
            risk_factors.append("Complex procedure requiring review")
        
        return {
            'openai_confidence': max(0.1, min(0.9, approval_prob)),
            'medical_necessity': 'Medium',
            'clinical_reasoning': reasoning,
            'risk_factors': risk_factors,
            'clinical_notes': 'Rule-based clinical assessment applied'
        }
    
    def predict_with_clinical_ai(self, claim: Dict[str, Any]) -> Dict[str, Any]:
        """Comprehensive prediction using ClinicalBERT + OpenAI ensemble"""
        
        # Create clinical narrative
        clinical_text = self.create_clinical_narrative(claim)
        
        # Get ClinicalBERT analysis
        bert_analysis = self.get_clinical_bert_analysis(clinical_text)
        
        # Get OpenAI clinical reasoning
        openai_analysis = self.get_openai_clinical_reasoning(clinical_text)
        
        # Ensemble weighting: ClinicalBERT (30%) + OpenAI (50%) + Rules (20%)
        rule_based_prob = self._get_rule_based_probability(claim)
        
        ensemble_confidence = (
            bert_analysis['bert_confidence'] * 0.30 +
            openai_analysis['openai_confidence'] * 0.50 +
            rule_based_prob * 0.20
        )
        
        # Final prediction
        prediction = 'APPROVED' if ensemble_confidence > 0.5 else 'DENIED'
        
        # Compile comprehensive result
        result = {
            'prediction': prediction,
            'confidence': ensemble_confidence,
            'clinical_bert_confidence': bert_analysis['bert_confidence'],
            'openai_confidence': openai_analysis['openai_confidence'],
            'rule_based_confidence': rule_based_prob,
            'medical_necessity': openai_analysis.get('medical_necessity', 'Medium'),
            'clinical_reasoning': openai_analysis.get('clinical_reasoning', []),
            'risk_factors': openai_analysis.get('risk_factors', []),
            'clinical_notes': openai_analysis.get('clinical_notes', ''),
            'clinical_text_preview': clinical_text[:300] + "...",
            'ai_models_used': self._get_active_models()
        }
        
        # Store prediction history
        self.prediction_history.append(result)
        
        return result
    
    def _get_rule_based_probability(self, claim: Dict[str, Any]) -> float:
        """Get rule-based approval probability"""
        
        procedure_code = str(claim.get('Procedure Code', ''))
        billed_amount = float(claim.get('Billed Amount', 0))
        insurance_type = str(claim.get('Insurance Type', ''))
        
        # Base approval rate
        prob = 0.75
        
        # Procedure type adjustments
        if procedure_code in self.medical_patterns['preventive_care']:
            prob = self.clinical_guidelines['approval_criteria']['preventive_care']
        elif procedure_code in self.medical_patterns['emergency_procedures']:
            prob = self.clinical_guidelines['approval_criteria']['emergency_care']
        elif procedure_code in self.medical_patterns['mental_health_procedures']:
            prob = self.clinical_guidelines['approval_criteria']['mental_health']
        elif procedure_code in self.medical_patterns['high_risk_procedures']:
            prob = self.clinical_guidelines['approval_criteria']['complex_procedures']
        
        # Cost adjustments
        if billed_amount > self.clinical_guidelines['cost_thresholds']['very_high_cost']:
            prob *= 0.7
        elif billed_amount > self.clinical_guidelines['cost_thresholds']['high_cost']:
            prob *= 0.85
        
        # Insurance type adjustments
        if insurance_type == 'Self-Pay':
            prob *= 0.9
        
        return max(0.1, min(0.9, prob))
    
    def _get_active_models(self) -> List[str]:
        """Get list of active AI models"""
        models = ['Rule-based Clinical Guidelines']
        
        if self.clinical_bert_classifier:
            models.append('ClinicalBERT (MIMIC-III)')
        
        if self.openai_client:
            models.append('OpenAI GPT-4 Clinical Reasoning')
        
        return models
    
    def train_on_claims_data(self, df: pd.DataFrame) -> None:
        """Train/calibrate the clinical AI ensemble"""
        print("üè• Training Clinical AI Ensemble (ClinicalBERT + OpenAI)...")
        
        # Analyze clinical patterns
        self.clinical_patterns = {
            'denial_rates': {
                'by_procedure': df.groupby('Procedure Code')['Outcome'].apply(lambda x: (x == 'Denied').mean()).to_dict(),
                'by_diagnosis': df.groupby('Diagnosis Code')['Outcome'].apply(lambda x: (x == 'Denied').mean()).to_dict(),
                'by_insurance': df.groupby('Insurance Type')['Outcome'].apply(lambda x: (x == 'Denied').mean()).to_dict(),
                'overall': (df['Outcome'] == 'Denied').mean()
            },
            'cost_analysis': {
                'denied_avg_cost': df[df['Outcome'] == 'Denied']['Billed Amount'].mean(),
                'approved_avg_cost': df[df['Outcome'] == 'Approved']['Billed Amount'].mean()
            }
        }
        
        self.is_trained = True
        
        print("‚úÖ Clinical AI Ensemble trained successfully")
        print(f"   Overall denial rate: {self.clinical_patterns['denial_rates']['overall']:.3f}")
        print(f"   Models active: {', '.join(self._get_active_models())}")
        print(f"   Clinical patterns analyzed: {len(self.clinical_patterns['denial_rates']['by_procedure'])} procedures")
    
    def evaluate_performance(self, test_df: pd.DataFrame, num_samples: int = 25) -> Dict[str, Any]:
        """Evaluate Clinical AI Ensemble performance"""
        
        if not self.is_trained:
            print("‚ö†Ô∏è Model not trained. Please call train_on_claims_data() first.")
            return {}
        
        print(f"üîç Evaluating Clinical AI Ensemble on {num_samples} test claims...")
        
        test_sample = test_df.sample(n=min(num_samples, len(test_df)), random_state=42)
        
        predictions = []
        confidences = []
        actual_outcomes = []
        medical_necessities = []
        
        for i, (_, claim) in enumerate(test_sample.iterrows()):
            if i % 5 == 0:
                print(f"   Processing claim {i+1}/{len(test_sample)}...")
            
            # Get prediction
            result = self.predict_with_clinical_ai(claim.to_dict())
            
            predictions.append(result['prediction'])
            confidences.append(result['confidence'])
            medical_necessities.append(result['medical_necessity'])
            
            # Actual outcome
            actual = 'DENIED' if claim['Outcome'] == 'Denied' else 'APPROVED'
            actual_outcomes.append(actual)
        
        # Calculate metrics
        accuracy = accuracy_score(actual_outcomes, predictions)
        avg_confidence = np.mean(confidences)
        
        # Medical necessity breakdown
        necessity_counts = {necessity: medical_necessities.count(necessity) 
                           for necessity in ['High', 'Medium', 'Low']}
        
        results = {
            'accuracy': accuracy,
            'avg_confidence': avg_confidence,
            'total_predictions': len(predictions),
            'correct_predictions': sum(p == a for p, a in zip(predictions, actual_outcomes)),
            'medical_necessity_distribution': necessity_counts,
            'active_models': self._get_active_models(),
            'clinical_bert_available': self.clinical_bert_classifier is not None,
            'openai_available': self.openai_client is not None
        }
        
        print(f"üìä Clinical AI Ensemble Results:")
        print(f"   Accuracy: {accuracy:.3f}")
        print(f"   Average Confidence: {avg_confidence:.3f}")
        print(f"   Active Models: {', '.join(results['active_models'])}")
        print(f"   Medical Necessity Distribution: {necessity_counts}")
        
        return results

def main():
    """Test Clinical AI Ensemble"""
    print("üöÄ Testing ClinicalBERT + OpenAI Clinical AI Ensemble")
    print("=" * 65)
    
    # Load test data
    try:
        df = pd.read_csv('../data/enhanced_claim_data.csv')
        test_df = pd.read_csv('../data/test_claims.csv')
        print(f"üìÇ Loaded {len(df)} training and {len(test_df)} test claims")
    except FileNotFoundError:
        print("‚ö†Ô∏è Data files not found. Please ensure data files are in ../data/ directory")
        return
    
    # Initialize Clinical AI Ensemble
    predictor = ClinicalBERTOpenAIPredictor()
    
    # Train/calibrate
    predictor.train_on_claims_data(df)
    
    # Test sample predictions
    print(f"\nüîç Testing sample clinical AI predictions...")
    sample_claims = test_df.head(2)
    
    for i, (_, claim) in enumerate(sample_claims.iterrows(), 1):
        print(f"\n--- Clinical AI Test {i} ---")
        result = predictor.predict_with_clinical_ai(claim.to_dict())
        
        actual = 'DENIED' if claim['Outcome'] == 'Denied' else 'APPROVED'
        
        print(f"Procedure: {claim['Procedure Code']} | Diagnosis: {claim['Diagnosis Code']}")
        print(f"Predicted: {result['prediction']} (Confidence: {result['confidence']:.3f})")
        print(f"Actual: {actual}")
        print(f"Medical Necessity: {result['medical_necessity']}")
        print(f"AI Models Used: {', '.join(result['ai_models_used'])}")
        print(f"Clinical Reasoning: {'; '.join(result['clinical_reasoning'][:2])}")
    
    # Full evaluation
    evaluation_results = predictor.evaluate_performance(test_df, num_samples=15)
    
    print(f"\nüéâ Clinical AI Ensemble testing complete!")
    print(f"üè• Advanced medical AI ready for healthcare claim analysis!")

if __name__ == "__main__":
    main() 